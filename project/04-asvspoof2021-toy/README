General
----------
This project is a toy example to train and run evaluation on a LFCC-LCNN LSTM system.
The toy data set contains only a few utterances. It will help to show how
the project works and how it can be used for other database.

Another implementation is in the github of ASVspoof https://github.com/asvspoof-challenge/2021.
The LFCC-LCNN there is similar, but some APIs are changed.


Usage
----------

1. Using toy dat set to do training and evaluation 
   Either run the single script
   $: bash 00_toy_example.sh

2. Using a quick wrapper to evaluate a new evaluation set
   (although we will use the evaluation set in the toy data set)
   $: bash 00_wrapper_eval.sh

Walking through the first script shows how to use this project to train and evaluate
a data set. It is useful if you want work on real data sets.
Of course, the data set directory and related configuration file must be prepared.
After running 00_toy_example.sh, you will see how the data set is prepared in DATA/toy_example.
And you can check how configuration is done in */config.py


Walking through the second script shows the conveninent way to run evaluation on 
different evaluation sets. Just provide the directory of waveform to be evaluated, 
the trained model, and an arbitary name for the evaluation set. That's all.


Folder structure
----------------
Files marked with = are generated after running 00_toy_example.sh.

|- DATA
|  |- toy_example.tar.gz: toy dataset package
|  |= toy_example
|  |  |= protocol.txt: 
|  |  |   protocol file
|  |  |   this will be loaded by pytorch code for training and evaluation
|  |  |= scp: 
|  |  |   list of files for traing, dev, and eval
|  |  |= train_dev: 
|  |  |   waveform for train and validation sets   
|  |  |= eval: 
|  |  |   waveform for evaluation sets   
|
|- lfcc-lcnn-lstmsum-sig_toy_example
|  |  folder for the toy example
|  |  |- 00_train.sh: recipe to train the model
|  |  |- 01_eval.sh: command line to evaluate the model on eval set
|  |  |- main.py: main function
|  |  |- config.py: configuration file
|  |  |- model.py: definition of model in Pytorch code
|  |  |- __pretrained
|  |  |    |- trained_network.pt: pre-trained model 
|  |  |    |   from ../03-asvspoof-mega/lfcc-lcnn-lstmsum-sig/01
|  |  |= epochNNN.pt: trained model after NNN-th epoch
|  |  |= trained_network.pt: trained model after the full training process
|  |  |= asvspoof2021_*_toy_utt_length.dic: 
|  |  |    cache files to save the duration information of each trial
|  |  |    they are automatically generated by the code
|  |  |    they can be deleted freely
|  |  |= log_train.txt: training log
|  |  |= log_err.txt: error log (it also contains the training loss of each trial)
|  |  |= log_eval.txt: evaluation log
|  |  |= log_eval_score.txt: score of each trial, extracted from log_eval.txt
|  |  |= log_eval_err.txt: error log 

log_train.txt is self-explanable.

log_eval_score.txt has four columns (see Note 2):
  Output, File name, label, score
  Output, LA_E_1066571, 1, 19.160793


Note
----------
1. If GPU memory is insufficient, please reduce --batch-size in */00_train.sh

2. Output score has this following format:

   Output, File name, label, score
   Output, LA_E_8688127, 0, -0.011127

   If label of the trial is given in the protocol file, the label will be: 
     0, which denotes spoof
     1, which denotes bona fide

   If label of the trial is not given in the protocol file, the label will be:
    -1, which means unknown (not provided)

3. Accordingly, the code assumes 0 and 1 as the labels for spoof and bona fide
   trials, respectively. 

4. Although you can use arbiary string to name the data set in config.py and
   02_eval_alternative.sh, it is better to use a meaningful name and differentiate 
   the names for different data sets. 
   Here, we use asvspoof2021_train_toy, asvspoof2021_val_toy, asvspoof2021_eval_toy
   in config.py.

5. Please check ../03-asvspoof-mega if you want to use other models. 
   However, model.py ../03-asvspoof-mega assumes that trial labels are available 
   for evaluation set (as post-challenge experiments on ASVspoof2019 LA).

   For a new evaluation set whose trial labels are unknown, please create
   protocol.txt using dummy labels for the trials. 
   Or, please modify protocol_parse() and _get_target_eval() 
   following the definition in lfcc-lcnn-lstm-sig_toy_example/model.py

   (Apologize that I don't have the time to modify the model.py in 03-asvspoof-mega 
    one by one)
     
6. The used countermeasure model is detailed here https://arxiv.org/abs/2103.11326.


For a high-level explanation on how the functions and objects work in the script, please
check ../../README.md


That's all